# Assignment Feedback: Week 4: Dimensionality Reduction

**Student:** jerryc233333
**Total Score:** 24/40 (60.0%)

**Grade Category:** D (Poor)

---

## Problem Breakdown

### Exercise 1 (4/16 = 25.0%)

**Part pipeline-part1** (pipeline-part1.code): 0/0 points

_Feedback:_ Nice job: you applied PCA (2 components) and visualized MNIST with a clear scatter and colorbar—this meets the task. If you wanted to emphasize “approximation,” you could also inverse_transform some test images to show reconstructions.

**Part pipeline-part2** (pipeline-part2.code): 1/4 points

_Feedback:_ You correctly applied PCA and produced a scree plot, but the task required a 2D scatter plot of the data colored by class. Reduce to 2 components (n_components=2), transform X, and scatter plot X[:,0] vs X[:,1] with c=y. Using your prior pca_vis/X_vis would satisfy this.

**Part pipeline-part3** (pipeline-part3.code): 1/4 points

_Feedback:_ You computed cumulative variance and 95% components, but this step requires a scree plot of the first 40 components with y-axis as percent variance explained. No plot produced, not restricted to 40, and not percent. Use your PCA(40) and plot explained_variance_ratio_*100.

**Part pipeline-part4** (pipeline-part4.code): 2/4 points

_Feedback:_ You applied PCA and did reconstructions, but you didn’t calculate or report the number of components for 95% variance here, nor use your previously computed n_components_95. Please compute cumulative explained variance and derive n_components (or reuse n_components_95) and print 

**Part pipeline-part5** (pipeline-part5.code): 0/4 points

_Feedback:_ This cell doesn’t address Step 5. You were asked to visualize a digit reconstructed from the reduced space using the dimensions from Step 4 (e.g., your 148-component PCA) and plot it. Instead, you trained/evaluated KNN with/without PCA. No visualization provided.

---

### Exercise 2 (10/10 = 100.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Great job. You correctly applied t-SNE to MNIST and produced a colored 2D scatter with labels and a colorbar. Parameters are sensible and the plot is clear. As a refinement, consider PCA preprocessing or subsampling for speed, but your solution meets the goal.

**Part ex1-part2** (ex1-part2.code): 3/3 points

_Feedback:_ Good job: you used t-SNE embeddings with KNN and reported accuracy, answering “how does it perform.” Note that fitting t-SNE on the combined train+test leaks test info into training; consider using a train-only fit (or a parametric DR like UMAP/PCA) to avoid leakage.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job. You fit UMAP on the training set, transformed train/test, trained KNN, and computed accuracy. Clear, correct, and aligned with prior work. Using 30D is fine. No issues spotted.

---

### Exercise 4 (10/14 = 71.4%)

**Part ex2-part1** (ex2-part1.code): 0/0 points

_Feedback:_ You implemented PCA (2D/3D) with KNN and visualizations—good start. However, you didn’t explore UMAP or its parameters, didn’t vary KNN settings, and evaluated on the training set only. Also, the second cell is empty. Add UMAP, tune params, use a test split, and compare accuracie

**Part ex2-part2** (ex2-part2.code): 3/7 points

_Feedback:_ You used UMAP instead of PCA, not following the instruction and not leveraging your prior PCA work. The pipeline (DR + KNN + visualization) is otherwise reasonable and likely runs. For full credit, replace UMAP with PCA and report the PCA-based results.

**Part ex2-part3** (ex2-part3.answer): 7/7 points

_Feedback:_ Good reasoning: you correctly contrast PCA’s linear variance capture with UMAP’s neighborhood preservation and explain why noisy x/y can swamp a modest z shift, blending classes. Clear, dataset-specific intuition. For completeness, you could note tuning n_neighbors/min_dist or sc

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-10-27 18:51:17 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*